{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "In the scope of the DARGMINTS project, an annotation project was carried out which consisted of annotating argumentation structures in opinion articles published in the Público newspaper. The annotation included several layers:\n",
    "\n",
    "1. Selecting text spans that are taken to have an argumentative role (either as premises or conclusions of arguments) -- these are Argumentative Discourse Units (ADU).\n",
    "2. Connecting such ADUs through support or attack relations.\n",
    "3. Classifying the propositional content of ADUs as propositions of fact, propositions of value, or propositions of policy; within propositions of value, distinguish between those with a positive (+) or negative (-) connotation.\n",
    "\n",
    "In a proposition of fact, the content corresponds to a piece of information that can be checked for truthness. This does not usually happen with propositions of value, which denote value judgments with a strong subjective nature; often, they also have a (positive or negative) polarity attached. A proposition of policy prescribes or suggests a certain line of action, often mentioning the agents or entities that are capable of carrying out such policies.\n",
    "\n",
    "The aim of this assignment is to build a classifier of types of ADUs, thus focusing on the last annotation step described above. For that, you have access to two different files:\n",
    "\n",
    "- A file containing the content of each annotated ADU span and its 5-class classification: Value, Value(+), Value(-), Fact, or Policy. For each ADU, we also know the annotator and the document from which it has been taken.\n",
    "- A file containing details for each opinion article that has been annotated, including the full article content.\n",
    "Besides ADU contents, you can make use of any contextual information provided in the corresponding opinion article.\n",
    "\n",
    "Each opinion article has been annotated by 3 different annotators. For that reason, you will find in the ADU file an indication of which annotator has obtained the ADU. It may happen that the same ADU has been annotated by more than one annotator. When that is the case, they do not necessarily agree on the type of proposition.\n",
    "\n",
    "How good a classifier (or set of classifiers) can you get? Don't forget to properly split the dataset in a sensible manner, so that you have a proper test set. Start by obtaining an arbitrary baseline, against which you can then compare your improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portuguese NLKT: https://www.nltk.org/howto/portuguese_en.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('OpArticles/OpArticles.xlsx')\n",
    "data_ADU = pd.read_excel('OpArticles/OpArticles_ADUs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Articles Data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>body</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>topics</th>\n",
       "      <th>keywords</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url_canonical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d04a31b896a7fea069ef06f</td>\n",
       "      <td>Pouco pão e muito circo, morte e bocejo</td>\n",
       "      <td>['José Vítor Malheiros']</td>\n",
       "      <td>O poeta espanhol António Machado escrevia, uns...</td>\n",
       "      <td>É tudo cómico na FIFA, porque todos os dias a ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>['Brasil', 'Campeonato do Mundo', 'Desporto', ...</td>\n",
       "      <td>2014-06-17 00:16:00</td>\n",
       "      <td>https://www.publico.pt/2014/06/17/desporto/opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d04a3fc896a7fea069f0717</td>\n",
       "      <td>Portugal nos Mundiais de Futebol de 2010 e 2014</td>\n",
       "      <td>['Rui J. Baptista']</td>\n",
       "      <td>“O mais excelente quadro posto a uma luz logo ...</td>\n",
       "      <td>Deve ser evidenciado o clima favorável criado ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>['Brasil', 'Campeonato do Mundo', 'Coreia do N...</td>\n",
       "      <td>2014-07-05 02:46:00</td>\n",
       "      <td>https://www.publico.pt/2014/07/05/desporto/opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d04a455896a7fea069f07ab</td>\n",
       "      <td>Futebol, guerra, religião</td>\n",
       "      <td>['Fernando Belo']</td>\n",
       "      <td>1. As sociedades humanas parecem ser regidas p...</td>\n",
       "      <td>O futebol parece ser um sucedâneo quer da lei ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>['A guerra na Síria', 'Desporto', 'Futebol', '...</td>\n",
       "      <td>2014-07-12 16:05:33</td>\n",
       "      <td>https://www.publico.pt/2014/07/12/desporto/opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d04a52f896a7fea069f0921</td>\n",
       "      <td>As razões do Qatar para acolher o Mundial em 2022</td>\n",
       "      <td>['Hamad bin Khalifa bin Ahmad Al Thani']</td>\n",
       "      <td>Este foi um Mundial incrível. Vimos actuações ...</td>\n",
       "      <td>Queremos cooperar plenamente com a investigaçã...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>['Desporto', 'FIFA', 'Futebol', 'Mundial de fu...</td>\n",
       "      <td>2014-07-27 02:00:00</td>\n",
       "      <td>https://www.publico.pt/2014/07/27/desporto/opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d04a8d7896a7fea069f6997</td>\n",
       "      <td>A política no campo de futebol</td>\n",
       "      <td>['Carlos Nolasco']</td>\n",
       "      <td>O futebol sempre foi um jogo aparentemente sim...</td>\n",
       "      <td>Retirar a expressão política do futebol é reti...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>['Albânia', 'Campeonato da Europa', 'Desporto'...</td>\n",
       "      <td>2014-10-23 00:16:00</td>\n",
       "      <td>https://www.publico.pt/2014/10/23/desporto/opi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_id  \\\n",
       "0  5d04a31b896a7fea069ef06f   \n",
       "1  5d04a3fc896a7fea069f0717   \n",
       "2  5d04a455896a7fea069f07ab   \n",
       "3  5d04a52f896a7fea069f0921   \n",
       "4  5d04a8d7896a7fea069f6997   \n",
       "\n",
       "                                               title  \\\n",
       "0            Pouco pão e muito circo, morte e bocejo   \n",
       "1    Portugal nos Mundiais de Futebol de 2010 e 2014   \n",
       "2                          Futebol, guerra, religião   \n",
       "3  As razões do Qatar para acolher o Mundial em 2022   \n",
       "4                     A política no campo de futebol   \n",
       "\n",
       "                                    authors  \\\n",
       "0                  ['José Vítor Malheiros']   \n",
       "1                       ['Rui J. Baptista']   \n",
       "2                         ['Fernando Belo']   \n",
       "3  ['Hamad bin Khalifa bin Ahmad Al Thani']   \n",
       "4                        ['Carlos Nolasco']   \n",
       "\n",
       "                                                body  \\\n",
       "0  O poeta espanhol António Machado escrevia, uns...   \n",
       "1  “O mais excelente quadro posto a uma luz logo ...   \n",
       "2  1. As sociedades humanas parecem ser regidas p...   \n",
       "3  Este foi um Mundial incrível. Vimos actuações ...   \n",
       "4  O futebol sempre foi um jogo aparentemente sim...   \n",
       "\n",
       "                                    meta_description  topics  \\\n",
       "0  É tudo cómico na FIFA, porque todos os dias a ...  Sports   \n",
       "1  Deve ser evidenciado o clima favorável criado ...  Sports   \n",
       "2  O futebol parece ser um sucedâneo quer da lei ...  Sports   \n",
       "3  Queremos cooperar plenamente com a investigaçã...  Sports   \n",
       "4  Retirar a expressão política do futebol é reti...  Sports   \n",
       "\n",
       "                                            keywords         publish_date  \\\n",
       "0  ['Brasil', 'Campeonato do Mundo', 'Desporto', ...  2014-06-17 00:16:00   \n",
       "1  ['Brasil', 'Campeonato do Mundo', 'Coreia do N...  2014-07-05 02:46:00   \n",
       "2  ['A guerra na Síria', 'Desporto', 'Futebol', '...  2014-07-12 16:05:33   \n",
       "3  ['Desporto', 'FIFA', 'Futebol', 'Mundial de fu...  2014-07-27 02:00:00   \n",
       "4  ['Albânia', 'Campeonato da Europa', 'Desporto'...  2014-10-23 00:16:00   \n",
       "\n",
       "                                       url_canonical  \n",
       "0  https://www.publico.pt/2014/06/17/desporto/opi...  \n",
       "1  https://www.publico.pt/2014/07/05/desporto/opi...  \n",
       "2  https://www.publico.pt/2014/07/12/desporto/opi...  \n",
       "3  https://www.publico.pt/2014/07/27/desporto/opi...  \n",
       "4  https://www.publico.pt/2014/10/23/desporto/opi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ADU Data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>node</th>\n",
       "      <th>ranges</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d04a31b896a7fea069ef06f</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>[[2516, 2556]]</td>\n",
       "      <td>O facto não é apenas fruto da ignorância</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d04a31b896a7fea069ef06f</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>[[2568, 2806]]</td>\n",
       "      <td>havia no seu humor mais jornalismo (mais inves...</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d04a31b896a7fea069ef06f</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>[[3169, 3190]]</td>\n",
       "      <td>É tudo cómico na FIFA</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d04a31b896a7fea069ef06f</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>[[3198, 3285]]</td>\n",
       "      <td>o que todos nós permitimos que esta organizaçã...</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d04a31b896a7fea069ef06f</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>[[4257, 4296]]</td>\n",
       "      <td>não nos fazem rir à custa dos poderosos</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_id annotator  node          ranges  \\\n",
       "0  5d04a31b896a7fea069ef06f         A     0  [[2516, 2556]]   \n",
       "1  5d04a31b896a7fea069ef06f         A     1  [[2568, 2806]]   \n",
       "2  5d04a31b896a7fea069ef06f         A     3  [[3169, 3190]]   \n",
       "3  5d04a31b896a7fea069ef06f         A     4  [[3198, 3285]]   \n",
       "4  5d04a31b896a7fea069ef06f         A     6  [[4257, 4296]]   \n",
       "\n",
       "                                              tokens  label  \n",
       "0           O facto não é apenas fruto da ignorância  Value  \n",
       "1  havia no seu humor mais jornalismo (mais inves...  Value  \n",
       "2                              É tudo cómico na FIFA  Value  \n",
       "3  o que todos nós permitimos que esta organizaçã...  Value  \n",
       "4            não nos fazem rir à custa dos poderosos  Value  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "display(\"Articles Data\", data.head())\n",
    "display(\"ADU Data\", data_ADU.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Articles---------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 373 entries, 0 to 372\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   article_id        373 non-null    object\n",
      " 1   title             373 non-null    object\n",
      " 2   authors           373 non-null    object\n",
      " 3   body              373 non-null    object\n",
      " 4   meta_description  373 non-null    object\n",
      " 5   topics            373 non-null    object\n",
      " 6   keywords          373 non-null    object\n",
      " 7   publish_date      373 non-null    object\n",
      " 8   url_canonical     373 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 26.4+ KB\n",
      "---------------------ADU---------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16743 entries, 0 to 16742\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   article_id  16743 non-null  object\n",
      " 1   annotator   16743 non-null  object\n",
      " 2   node        16743 non-null  int64 \n",
      " 3   ranges      16743 non-null  object\n",
      " 4   tokens      16743 non-null  object\n",
      " 5   label       16743 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 785.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------Articles---------------------\")\n",
    "data.info()\n",
    "print(\"---------------------ADU---------------------\")\n",
    "data_ADU.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Articles data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>body</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>topics</th>\n",
       "      <th>keywords</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url_canonical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>372</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5cf46cea896a7fea06003dd2</td>\n",
       "      <td>Como parar a charlatanice que são as medicinas...</td>\n",
       "      <td>['Jean-Michel Casa', 'Christof Weil']</td>\n",
       "      <td>Atualmente, o excesso de peso é o principal re...</td>\n",
       "      <td>Temos de “atacar” a máquina fiscal espanhola. ...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>['Desporto', 'Opinião']</td>\n",
       "      <td>2016-08-04 00:30:00</td>\n",
       "      <td>https://www.publico.pt/2016/02/09/desporto/opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      article_id  \\\n",
       "count                        373   \n",
       "unique                       373   \n",
       "top     5cf46cea896a7fea06003dd2   \n",
       "freq                           1   \n",
       "\n",
       "                                                    title  \\\n",
       "count                                                 373   \n",
       "unique                                                373   \n",
       "top     Como parar a charlatanice que são as medicinas...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                      authors  \\\n",
       "count                                     373   \n",
       "unique                                    373   \n",
       "top     ['Jean-Michel Casa', 'Christof Weil']   \n",
       "freq                                        1   \n",
       "\n",
       "                                                     body  \\\n",
       "count                                                 373   \n",
       "unique                                                373   \n",
       "top     Atualmente, o excesso de peso é o principal re...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                         meta_description  topics  \\\n",
       "count                                                 373     373   \n",
       "unique                                                373       8   \n",
       "top     Temos de “atacar” a máquina fiscal espanhola. ...  Sports   \n",
       "freq                                                    1      52   \n",
       "\n",
       "                       keywords         publish_date  \\\n",
       "count                       373                  373   \n",
       "unique                      356                  372   \n",
       "top     ['Desporto', 'Opinião']  2016-08-04 00:30:00   \n",
       "freq                          4                    2   \n",
       "\n",
       "                                            url_canonical  \n",
       "count                                                 373  \n",
       "unique                                                373  \n",
       "top     https://www.publico.pt/2016/02/09/desporto/opi...  \n",
       "freq                                                    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ADU data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>node</th>\n",
       "      <th>ranges</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16743</td>\n",
       "      <td>16743</td>\n",
       "      <td>16743.000000</td>\n",
       "      <td>16743</td>\n",
       "      <td>16743</td>\n",
       "      <td>16743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>373</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11929</td>\n",
       "      <td>12008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5cf464b6896a7fea06ffbb9d</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0, 138]]</td>\n",
       "      <td>Não é verdade</td>\n",
       "      <td>Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>142</td>\n",
       "      <td>5226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.938960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.033932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      article_id annotator          node      ranges  \\\n",
       "count                      16743     16743  16743.000000       16743   \n",
       "unique                       373         4           NaN       11929   \n",
       "top     5cf464b6896a7fea06ffbb9d         B           NaN  [[0, 138]]   \n",
       "freq                         142      5226           NaN           6   \n",
       "mean                         NaN       NaN     14.938960         NaN   \n",
       "std                          NaN       NaN     14.033932         NaN   \n",
       "min                          NaN       NaN      0.000000         NaN   \n",
       "25%                          NaN       NaN      4.000000         NaN   \n",
       "50%                          NaN       NaN     11.000000         NaN   \n",
       "75%                          NaN       NaN     21.000000         NaN   \n",
       "max                          NaN       NaN    100.000000         NaN   \n",
       "\n",
       "               tokens  label  \n",
       "count           16743  16743  \n",
       "unique          12008      5  \n",
       "top     Não é verdade  Value  \n",
       "freq                8   8102  \n",
       "mean              NaN    NaN  \n",
       "std               NaN    NaN  \n",
       "min               NaN    NaN  \n",
       "25%               NaN    NaN  \n",
       "50%               NaN    NaN  \n",
       "75%               NaN    NaN  \n",
       "max               NaN    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Articles data\", data.describe(include='all'))\n",
    "display(\"ADU data\", data_ADU.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column2string(column):\n",
    "    str_result = \"\"\n",
    "    for i in column:\n",
    "        str_result += i + \"\"\n",
    "    return str_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portuguese nltk\n",
    "import nltk.test.portuguese_en_fixt \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "portuguese_tokenizer=nltk.data.load('tokenizers/punkt/portuguese.pickle')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o fact não é apen frut da ignor\n",
      "hav no seu hum mais jorn (mal investigação, mais preocup em aprofund e contextual a história, mais isenç no relato, mais preocup social, mais urg de denunciar) do que em muit peç real jorn\n",
      "é tud cómic na fif\n",
      "o que tod nó permit que est organiz faç é total absurd e sem sent\n",
      "não no faz rir à cust do poder\n"
     ]
    }
   ],
   "source": [
    "import nltk.stem\n",
    "\n",
    "corpus = []\n",
    "counter = 0\n",
    "ps = nltk.stem.RSLPStemmer()\n",
    "for i in range(0, data_ADU['tokens'].size):\n",
    "    token = data_ADU['tokens'][i]\n",
    "    # to lower-case\n",
    "    token = token.lower()\n",
    "    # split into tokens, apply stemming and remove stop words\n",
    "    token = ' '.join([ps.stem(w) for w in token.split()])\n",
    "    corpus.append(token)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16743\n",
      "16743\n"
     ]
    }
   ],
   "source": [
    "print(data_ADU['tokens'].size)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "#lemmatizer = LemmatizerModel.pretrained(\"lemma\", \"pt\") \\\n",
    "#        .setInputCols([\"token\"]) \\\n",
    "#        .setOutputCol(\"lemma\")\n",
    "#nlp_pipeline = Pipeline(stages=[document_assembler, tokenizer, lemmatizer])\n",
    "#light_pipeline = LightPipeline(nlp_pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\")))\n",
    "#results = light_pipeline.fullAnnotate(text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16743, 12599)\n",
      "(16743, 12599) (16743,)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "y = data_ADU['label']\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13394, 12599) (13394,)\n",
      "(3349, 12599) (3349,)\n",
      "\n",
      "Label distribution in the training set:\n",
      "Value       6422\n",
      "Fact        2967\n",
      "Value(-)    2339\n",
      "Value(+)    1137\n",
      "Policy       529\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Label distribution in the test set:\n",
      "Value       1680\n",
      "Fact         696\n",
      "Value(-)     561\n",
      "Value(+)     274\n",
      "Policy       138\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO - improve division\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "print(\"\\nLabel distribution in the training set:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nLabel distribution in the test set:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Model evaluation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def model_evaluation(y_pred, y_test):\n",
    "  print(\"------------------Confusion Matrix------------------\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "  print(\"------------------Accuracy------------------\")\n",
    "  print(accuracy_score(y_test, y_pred))\n",
    "  print(\"------------------Precision------------------\")\n",
    "  print(precision_score(y_test, y_pred, average=None))\n",
    "  print(\"------------------Recall------------------\")\n",
    "  print(recall_score(y_test, y_pred, average=None))\n",
    "  print(\"------------------F1------------------\")\n",
    "  print(f1_score(y_test, y_pred, average=None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Value' 'Value' 'Value(-)' ... 'Value' 'Value' 'Fact']\n"
     ]
    }
   ],
   "source": [
    "# TODO - Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clfNB = MultinomialNB()\n",
    "clfNB.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clfNB.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Confusion Matrix------------------\n",
      "[[ 246    1  398   14   37]\n",
      " [   9    7  122    0    0]\n",
      " [ 190    4 1368   22   96]\n",
      " [  32    0  201   31   10]\n",
      " [  55    1  354    2  149]]\n",
      "------------------Accuracy------------------\n",
      "0.5377724693938489\n",
      "------------------Precision------------------\n",
      "[0.46240602 0.53846154 0.55996725 0.44927536 0.51027397]\n",
      "------------------Recall------------------\n",
      "[0.35344828 0.05072464 0.81428571 0.11313869 0.26559715]\n",
      "------------------F1------------------\n",
      "[0.40065147 0.09271523 0.66359447 0.18075802 0.34935522]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonorgomes/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fact' 'Value' 'Value' ... 'Value' 'Value' 'Fact']\n",
      "------------------Confusion Matrix------------------\n",
      "[[ 249    1  371   21   54]\n",
      " [   9   43   79    2    5]\n",
      " [ 248   29 1183   74  146]\n",
      " [  25    6  152   76   15]\n",
      " [  61    7  283    4  206]]\n",
      "------------------Accuracy------------------\n",
      "0.5246342191699015\n",
      "------------------Precision------------------\n",
      "[0.42060811 0.5        0.57205029 0.42937853 0.48356808]\n",
      "------------------Recall------------------\n",
      "[0.35775862 0.3115942  0.70416667 0.27737226 0.36720143]\n",
      "------------------F1------------------\n",
      "[0.38664596 0.38392857 0.63127001 0.33702882 0.41742655]\n"
     ]
    }
   ],
   "source": [
    "# TODO - Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfLR = LogisticRegression()\n",
    "\n",
    "clfLR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clfLR.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "model_evaluation(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Value' 'Value(-)' 'Value' ... 'Fact' 'Fact' 'Fact']\n",
      "------------------Confusion Matrix------------------\n",
      "[[ 272    8  312   27   77]\n",
      " [   8   61   53    8    8]\n",
      " [ 315   64 1056   82  163]\n",
      " [  51    4  132   72   15]\n",
      " [  78    4  270    4  205]]\n",
      "------------------Accuracy------------------\n",
      "0.49746192893401014\n",
      "------------------Precision------------------\n",
      "[0.37569061 0.43262411 0.57926495 0.37305699 0.43803419]\n",
      "------------------Recall------------------\n",
      "[0.3908046  0.44202899 0.62857143 0.26277372 0.36541889]\n",
      "------------------F1------------------\n",
      "[0.38309859 0.43727599 0.60291179 0.30835118 0.39844509]\n"
     ]
    }
   ],
   "source": [
    "# TODO - Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clfDT = DecisionTreeClassifier()\n",
    "\n",
    "clfDT.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clfDT.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "model_evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Value' 'Value' 'Value' ... 'Value' 'Value' 'Fact']\n",
      "------------------Confusion Matrix------------------\n",
      "[[ 213    3  421   19   40]\n",
      " [   1   46   87    2    2]\n",
      " [ 168   30 1327   55  100]\n",
      " [  33    3  173   65    0]\n",
      " [  42    0  337    2  180]]\n",
      "------------------Accuracy------------------\n",
      "0.5467303672738131\n",
      "------------------Precision------------------\n",
      "[0.46608315 0.56097561 0.56588486 0.45454545 0.55900621]\n",
      "------------------Recall------------------\n",
      "[0.30603448 0.33333333 0.78988095 0.23722628 0.32085561]\n",
      "------------------F1------------------\n",
      "[0.36947095 0.41818182 0.65937888 0.3117506  0.40770102]\n"
     ]
    }
   ],
   "source": [
    "# TODO - Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfRF = RandomForestClassifier()\n",
    "\n",
    "clfRF.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clfRF.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "model_evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Value' 'Value' 'Value' ... 'Value' 'Value' 'Value']\n",
      "------------------Confusion Matrix------------------\n",
      "[[ 147    0  535    1   13]\n",
      " [   1   22  115    0    0]\n",
      " [  85   10 1543    7   35]\n",
      " [  12    1  243   18    0]\n",
      " [  14    0  471    0   76]]\n",
      "------------------Accuracy------------------\n",
      "0.5392654523738429\n",
      "------------------Precision------------------\n",
      "[0.56756757 0.66666667 0.53078775 0.69230769 0.61290323]\n",
      "------------------Recall------------------\n",
      "[0.2112069  0.15942029 0.91845238 0.06569343 0.13547237]\n",
      "------------------F1------------------\n",
      "[0.3078534  0.25730994 0.67277087 0.12       0.22189781]\n"
     ]
    }
   ],
   "source": [
    "# TODO - SVM \n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "clfSVC = svm.SVC()\n",
    "\n",
    "clfSVC.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clfSVC.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "model_evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
